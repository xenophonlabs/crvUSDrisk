{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# New Notebook Starts Here \n",
    "\n",
    "import csv\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import time\n",
    "import datetime\n",
    "\n",
    "def load_price_data(path_to_data_dir=\"../data/\",price_file=\"eth_usd_price\"):\n",
    "    with open(path_to_data_dir+price_file+\".csv\",\"r\") as infile:\n",
    "        try:\n",
    "            df = pd.read_csv(infile)\n",
    "            print(df.shape)\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "\n",
    "    df['datetime'] = pd.to_datetime(df['unix_timestamp'], unit='s')    \n",
    "    df.sort_values(by=\"unix_timestamp\", axis=0, ascending=True, inplace=True, kind='quicksort', na_position='last')\n",
    "    df['date'] = df['datetime'].dt.date\n",
    "    return(df)\n",
    "\n",
    "def process_daily_summary(price_data):\n",
    "    price_data[\"weighted_avg\"] = price_data[\"volume\"]*price_data[\"close\"]    \n",
    "    price_data['volatility'] = price_data['close'].pct_change()\n",
    "    \n",
    "    daily_price_data = price_data.groupby(\"date\").agg({\n",
    "        \"open\": \"first\",\n",
    "        \"high\": \"max\",\n",
    "        \"low\": \"min\",\n",
    "        \"close\": \"last\",\n",
    "        \"volume\": \"sum\",\n",
    "        \"unix_timestamp\": \"first\",\n",
    "        \"weighted_avg\": \"sum\",\n",
    "        \"volatility\": \"sum\",\n",
    "        })\n",
    "    \n",
    "    daily_price_data[\"weighted_avg\"] = daily_price_data[\"weighted_avg\"]/daily_price_data[\"volume\"]\n",
    "    return(daily_price_data)\n",
    "\n",
    "def price_analysis(daily_price_data,price_file = \"usdt_usdc_price\",\n",
    "                   jump_threshold=.04,recovery_mean=None,recovery_threshold=0.005,\n",
    "                   trunc_window_start=None,trunc_window_end=None):        \n",
    "    #### Compute GBM Mu and Sigma\n",
    "    daily_price_data['daily_return'] = daily_price_data['weighted_avg'].pct_change()\n",
    "    daily_price_data['log_daily_return'] = np.log(daily_price_data['weighted_avg'] / daily_price_data['weighted_avg'].shift(1))\n",
    "\n",
    "    # Drop NaN values (the first entry will be NaN due to the shift)\n",
    "    daily_price_data = daily_price_data.dropna()\n",
    "\n",
    "    # Calculate mean (mu) and standard deviation (sigma) of daily returns\n",
    "    mu = daily_price_data['log_daily_return'].mean()\n",
    "    sigma = daily_price_data['log_daily_return'].std()\n",
    "\n",
    "    print(\"Mean (mu) of daily returns:\", mu)\n",
    "    print(\"Standard deviation (sigma) of daily returns:\", sigma)\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(daily_price_data[\"weighted_avg\"])\n",
    "\n",
    "    #### Jump Diffusion - Magnitude Analysis\n",
    "    daily_price_data[\"drops\"]=(daily_price_data[\"high\"]-daily_price_data[\"low\"])/daily_price_data[\"weighted_avg\"]\n",
    "    counts,bin_edges = np.histogram(daily_price_data[\"drops\"],bins=100)\n",
    "    hist_daily_df = pd.DataFrame({\"Bin_Left_Edge\":bin_edges[:-1],\"Bin_Reft_Edge\":bin_edges[1:],\"Count\":counts})\n",
    "    plt.figure()\n",
    "    plt.hist(daily_price_data[\"drops\"],bins=100,log=True)\n",
    "    plt.title('Main Title')\n",
    "    plt.xlabel('Drop Size (%)')\n",
    "    plt.ylabel('# Days')\n",
    "    plt.show()\n",
    "\n",
    "    #### Jump Diffusion - Recovery Analysis     \n",
    "    recovery_times = []\n",
    "    jump_state = False\n",
    "    jump_timer=0    \n",
    "\n",
    "    daily_price_data[\"jump_state\"]=False\n",
    "    daily_price_data[\"recovery_mean\"]=recovery_mean    \n",
    "    daily_price_data[\"ema\"]=daily_price_data[\"weighted_avg\"].ewm(span=9, adjust=False).mean()\n",
    "\n",
    "    for index, row in daily_price_data.iterrows():    \n",
    "        jump_clear = abs(row[\"daily_return\"])>=jump_threshold\n",
    "        \n",
    "        if recovery_mean==None:            \n",
    "            daily_price_data.loc[index,\"recovery_mean\"] = daily_price_data.loc[index,\"ema\"]\n",
    "        in_recovery_range = abs(daily_price_data.loc[index,\"recovery_mean\"]-row[\"weighted_avg\"])<daily_price_data.loc[index,\"recovery_mean\"]*recovery_threshold\n",
    "        \n",
    "        if jump_state==True:\n",
    "            jump_timer+=1\n",
    "            if in_recovery_range:\n",
    "                recovery_times+=[jump_timer]\n",
    "                jump_state=False\n",
    "                jump_timer=0    \n",
    "            else:\n",
    "                pass\n",
    "        else: \n",
    "            if jump_clear:\n",
    "                jump_state=True\n",
    "            else:\n",
    "                pass    \n",
    "        daily_price_data.loc[index, \"jump_state\"] = jump_state\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(daily_price_data[\"daily_return\"])\n",
    "    plt.axhline(y=jump_threshold, color='r', linestyle='--')\n",
    "    plt.axhline(y=-1*jump_threshold, color='r', linestyle='--')\n",
    "\n",
    "    daily_price_data.index = pd.to_datetime(daily_price_data.index)\n",
    "    \n",
    "    if trunc_window_start!=None and trunc_window_end!=None:\n",
    "        trunc_daily_price_data = daily_price_data[(daily_price_data.index>=trunc_window_start) & (daily_price_data.index<=trunc_window_end)]\n",
    "    else:\n",
    "        trunc_daily_price_data = daily_price_data\n",
    "    plt.figure()\n",
    "    plt.plot(trunc_daily_price_data[\"weighted_avg\"],color = '#260099')\n",
    "    plt.plot(trunc_daily_price_data[\"recovery_mean\"], color='k', linestyle='--')\n",
    "    plt.plot(trunc_daily_price_data[\"recovery_mean\"]*(1+recovery_threshold), color='g', linestyle='--')\n",
    "    plt.plot(trunc_daily_price_data[\"recovery_mean\"]*(1-recovery_threshold), color='g', linestyle='--')\n",
    "    color= 'green'\n",
    "    for i, row in trunc_daily_price_data.iterrows():\n",
    "        left_edge = i - pd.to_timedelta(.5, unit='D')\n",
    "        right_edge = i + pd.to_timedelta(.5, unit='D')\n",
    "        if row['jump_state']==True: plt.axvspan(left_edge, right_edge, color=\"red\", alpha=0.2)\n",
    "        else: plt.axvspan(left_edge, right_edge, color=\"green\", alpha=0.1)    \n",
    "    plt.xticks(rotation=45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Stablecoin Price Analysis\n",
    "price_file=\"usdt_usdc_price\"\n",
    "price_data = load_price_data(path_to_data_dir=\"../data/\",price_file=price_file)\n",
    "daily_price_data = process_daily_summary(price_data)\n",
    "price_analysis(daily_price_data,price_file=price_file,\n",
    "               jump_threshold = .04,recovery_mean = 1,recovery_threshold = 0.01,\n",
    "               trunc_window_start=datetime.datetime(2023, 3, 1),\n",
    "               trunc_window_end=datetime.datetime(2023, 3, 30))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### ETH Price Analysis\n",
    "price_file=\"eth_usd_price\"\n",
    "price_data = load_price_data(path_to_data_dir=\"../data/\",price_file=price_file)\n",
    "daily_price_data = process_daily_summary(price_data)\n",
    "price_analysis(daily_price_data,price_file=price_file,\n",
    "               jump_threshold = .1,recovery_mean = None,recovery_threshold = 0.05,\n",
    "               trunc_window_start=None,\n",
    "               trunc_window_end=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### ETH and BTC Covariance Analysis from Coinbase\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "\n",
    "#### Read in ETH and BTC Price Data\n",
    "\n",
    "with open(\"../data/BTC-USD_price_86400_1641013200_to_1699315200.csv\", \"r\") as infile:\n",
    "    btc_data = pd.read_csv(infile)\n",
    "\n",
    "with open(\"../data/ETH-USD_price_86400_1641013200_to_1699315200.csv\", \"r\") as infile:\n",
    "    eth_data = pd.read_csv(infile)\n",
    "\n",
    "# Merge the data on the 'unix_timestamp' column\n",
    "merged_df = pd.merge(btc_data, eth_data, on=\"unix_timestamp\", how=\"inner\")\n",
    "merged_df.rename(columns={\"datetime_x\": \"datetime\", \"close_x\": \"BTC\", \"close_y\": \"ETH\"}, inplace=True)\n",
    "merged_df['datetime'] = pd.to_datetime(merged_df['datetime'])  # Convert to datetime\n",
    "merged_df['BTC_norm'] = merged_df['BTC'] / merged_df['BTC'].max()\n",
    "merged_df['ETH_norm'] = merged_df['ETH'] / merged_df['ETH'].max()\n",
    "\n",
    "### Plot ETH and BTC Coinbase Prices\n",
    "\n",
    "# Set global rcParams for font and spine visibility\n",
    "plt.rcParams[\"font.family\"] = \"serif\"\n",
    "plt.rcParams[\"font.size\"] = 10\n",
    "plt.rcParams[\"axes.spines.top\"] = False\n",
    "plt.rcParams[\"axes.spines.right\"] = True  # Enable the right spine\n",
    "\n",
    "# Set additional plot styling\n",
    "plt.rcParams[\"grid.color\"] = \"grey\"\n",
    "plt.rcParams[\"grid.linestyle\"] = \"--\"\n",
    "plt.rcParams[\"grid.linewidth\"] = 0.5\n",
    "\n",
    "# Create the figure and axis objects\n",
    "fig, ax1 = plt.subplots(figsize=(10, 5))\n",
    "\n",
    "# Plot BTC actual prices with label for the legend\n",
    "ax1.plot(merged_df['datetime'], merged_df['BTC'], label='BTC Price', color='orange')\n",
    "\n",
    "# Set labels and title for the first y-axis\n",
    "ax1.set_xlabel('Date')\n",
    "ax1.set_ylabel('BTC Price', color='orange')\n",
    "ax1.tick_params(axis='y', labelcolor='orange')\n",
    "\n",
    "# Create a second y-axis for the ETH prices\n",
    "ax2 = ax1.twinx()\n",
    "\n",
    "# Plot ETH actual prices with label for the legend\n",
    "ax2.plot(merged_df['datetime'], merged_df['ETH'], label='ETH Price', color='blue')\n",
    "\n",
    "# Set the label for the second y-axis\n",
    "ax2.set_ylabel('ETH Price', color='blue')\n",
    "ax2.tick_params(axis='y', labelcolor='blue')\n",
    "\n",
    "# Formatting dates on the x-axis\n",
    "ax1.xaxis.set_major_locator(mdates.AutoDateLocator())\n",
    "ax1.xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m-%d'))\n",
    "plt.xticks(rotation=45)  # Rotate dates for better spacing\n",
    "\n",
    "# Add title\n",
    "ax1.set_title('Coinbase BTC and ETH Prices Over Time')\n",
    "\n",
    "# Enable the grid\n",
    "ax1.grid(True)\n",
    "\n",
    "# Add a legend to the plot\n",
    "ax1.legend(loc='upper left')\n",
    "ax2.legend(loc='upper right')\n",
    "\n",
    "# Adjust the subplot to fit the figure area\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n",
    "\n",
    "\n",
    "#### Compute Correlation Coefficient using Pearson method\n",
    "corr = merged_df[\"BTC\"].corr(merged_df['ETH'],method='pearson')  # 'pearson' is the default method\n",
    "print(f\"The correlation coefficient between BTC and ETH is: {corr}\")\n",
    "\n",
    "\n",
    "#### Price Generator\n",
    "import sys\n",
    "sys.path.insert(0, '../')\n",
    "from src.sim.pricegenerator import PriceGenerator\n",
    "T = 1\n",
    "dt = 1/(365*24)\n",
    "\n",
    "price_generator = PriceGenerator()\n",
    "\n",
    "####### config2\n",
    "\n",
    "with open(\"../src/sim/configs/config_2.json\",\"r\") as infile:\n",
    "    config = json.load(infile)\n",
    "\n",
    "title = config[\"title\"]  # Title for the simulation, possibly used in plots or reporting\n",
    "assets = config[\"assets\"]  # List of asset identifiers to simulate\n",
    "type = config[\"type\"]  # Type of simulation to perform\n",
    "\n",
    "if type[0] == \"multi_corr\":\n",
    "    sparse_cor = config[\"sparse_cor\"]\n",
    "    assets = price_generator.gen_cor_jump_gbm2(assets, sparse_cor, T, dt)\n",
    "else:\n",
    "    sparse_cor = None\n",
    "    assets = price_generator.gen_jump_gbm2(assets, T, dt)\n",
    "\n",
    "price_generator.plot_gbms(T, dt, assets, title=title)\n",
    "\n",
    "########## config3\n",
    "\n",
    "with open(\"../src/sim/configs/config_3.json\",\"r\") as infile:\n",
    "    config = json.load(infile)\n",
    "\n",
    "title = config[\"title\"]  # Title for the simulation, possibly used in plots or reporting\n",
    "assets = config[\"assets\"]  # List of asset identifiers to simulate\n",
    "type = config[\"type\"]  # Type of simulation to perform\n",
    "\n",
    "if type[0] == \"multi_corr\":\n",
    "    sparse_cor = config[\"sparse_cor\"]\n",
    "    assets = price_generator.gen_cor_jump_gbm2(assets, sparse_cor, T, dt)\n",
    "else:\n",
    "    sparse_cor = None\n",
    "    assets = price_generator.gen_jump_gbm2(assets, T, dt)\n",
    "\n",
    "price_generator.plot_gbms(T, dt, assets, title=title)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
